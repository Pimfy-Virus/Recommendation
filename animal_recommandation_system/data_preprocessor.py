import pandas as pd
import numpy as np
import re
import pickle
import warnings
warnings.filterwarnings('ignore')

class AnimalDataProcessorForGPT:
    def __init__(self):
        self.processed_df = None
        
    def load_data(self, file_path):
        """CSV íŒŒì¼ ë¡œë“œ"""
        print("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")
        df = pd.read_csv(file_path)
        print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ, {len(df.columns)}ê°œ ì»¬ëŸ¼")
        return df
    
    def basic_cleaning(self, df):
        """ê¸°ë³¸ì ì¸ ë°ì´í„° ì •ë¦¬ (GPT ì„ë² ë”©ìš©)"""
        print("\nğŸ”§ ê¸°ë³¸ ë°ì´í„° ì •ë¦¬ ì¤‘...")
        
        df_clean = df.copy()
        
        # ëª¸ë¬´ê²Œ ë°ì´í„° íƒ€ì… ì •ë¦¬ë§Œ ìˆ˜í–‰ (ì´ìƒì¹˜ ìˆ˜ì • X)
        def clean_weight(weight):
            try:
                weight_float = float(weight)
                # ìŒìˆ˜ë‚˜ 0ì€ ë¬´íš¨ ì²˜ë¦¬
                if weight_float <= 0:
                    return np.nan
                return weight_float
            except:
                return np.nan
        
        df_clean['addinfo07'] = df_clean['addinfo07'].apply(clean_weight)
        
        # ì´ìƒì¹˜ í˜„í™©ë§Œ ë³´ê³ 
        outliers = df_clean[df_clean['addinfo07'] > 100]
        print(f"   - 100kg ì´ìƒ ëª¸ë¬´ê²Œ: {len(outliers)}ê°œ (ì›ë³¸ ìœ ì§€)")
        
        # ìŒìˆ˜ë‚˜ 0 ëª¸ë¬´ê²Œ ì²˜ë¦¬
        negative_weights = (df['addinfo07'].astype(str).str.contains('-', na=False)).sum()
        print(f"   - ë¹„ì •ìƒ ëª¸ë¬´ê²Œ {negative_weights}ê°œ ì œê±°")
        
        return df_clean
    
    def handle_missing_values(self, df):
        """ê²°ì¸¡ê°’ ì²˜ë¦¬ (GPTê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ)"""
        print("\nğŸ”„ ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...")
        
        df_clean = df.copy()
        
        # GPTê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •
        missing_fields = {
            'addinfo01': 'ì´ë¦„ë¯¸ì •',           # ë™ë¬¼ ì´ë¦„
            'addinfo02': 'êµ¬ì¡°ìœ„ì¹˜ë¯¸ì •',       # êµ¬ì¡° ìœ„ì¹˜
            'addinfo03': 'ì„±ë³„ë¯¸ì •',           # ì„±ë³„
            'addinfo04': 'ì¤‘ì„±í™”ì—¬ë¶€ë¯¸ì •',     # ì¤‘ì„±í™” ì—¬ë¶€
            'addinfo05': 'ë‚˜ì´ì •ë³´ì—†ìŒ',       # ë‚˜ì´
            'addinfo08': '',                   # ì„±ê²© í•´ì‹œíƒœê·¸ (ë¹ˆ ë¬¸ìì—´)
            'addinfo09': '',                   # êµ¬ì¡° ìŠ¤í† ë¦¬ (ë¹ˆ ë¬¸ìì—´)
            'addinfo10': '',                   # ì„±ê²© íŠ¹ì„± (ë¹ˆ ë¬¸ìì—´)
            'addinfo11': '',                   # ì¶”ê°€ ì •ë³´ (ë¹ˆ ë¬¸ìì—´)
            'addinfo16': '',                   # íŠ¹ë³„ ìš”êµ¬ì‚¬í•­ (ë¹ˆ ë¬¸ìì—´)
            'addinfo20': '',                   # ì¼ìƒ ê´€ë¦¬ ì •ë³´ (ë¹ˆ ë¬¸ìì—´)
            'state': 'ì…ì–‘ìƒíƒœë¯¸ì •',           # ì…ì–‘ ìƒíƒœ
            'kind': 'ì„ë³´ì¢…ë¥˜ë¯¸ì •'             # ì„ë³´ ì¢…ë¥˜
        }
        
        for field, default_value in missing_fields.items():
            if field in df_clean.columns:
                missing_count = df_clean[field].isna().sum()
                df_clean[field] = df_clean[field].fillna(default_value)
                if missing_count > 0:
                    print(f"   - {field}: {missing_count}ê°œ ê²°ì¸¡ê°’ â†’ '{default_value}'")
        
        # ëª¸ë¬´ê²Œ ê²°ì¸¡ê°’ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ (ìì—°ì–´ë¡œ ì²˜ë¦¬)
        weight_missing = df_clean['addinfo07'].isna().sum()
        if weight_missing > 0:
            print(f"   - ëª¸ë¬´ê²Œ ê²°ì¸¡ê°’ {weight_missing}ê°œ (ìì—°ì–´ í…ìŠ¤íŠ¸ì—ì„œ 'ëª¸ë¬´ê²Œ ì •ë³´ ì—†ìŒ'ìœ¼ë¡œ ì²˜ë¦¬ ì˜ˆì •)")
        
        return df_clean
    
    def create_size_category(self, weight):
        """ëª¸ë¬´ê²Œë¥¼ ìì—°ì–´ í¬ê¸° í‘œí˜„ìœ¼ë¡œ ë³€í™˜"""
        if pd.isna(weight):
            return "ëª¸ë¬´ê²Œ ì •ë³´ ì—†ìŒ"
        
        try:
            weight = float(weight)
            if weight < 7:
                return "ì†Œí˜• (7kg ë¯¸ë§Œ)"
            elif weight < 20:
                return "ì¤‘í˜• (7-20kg)"
            else:
                return "ëŒ€í˜• (20kg ì´ìƒ)"
        except:
            return "ëª¸ë¬´ê²Œ ì •ë³´ ì—†ìŒ"
    
    def create_age_description(self, age_info):
        """ë‚˜ì´ ì •ë³´ë¥¼ ìì—°ì–´ë¡œ ë³€í™˜"""
        if pd.isna(age_info) or age_info == 'ë‚˜ì´ì •ë³´ì—†ìŒ':
            return "ë‚˜ì´ ì •ë³´ ì—†ìŒ"
        
        age_str = str(age_info).lower()
        
        # ì—°ë„ ê¸°ë°˜ ë¶„ë¥˜
        if any(year in age_str for year in ['2024', '2023']):
            return "ì–´ë¦° ë™ë¬¼ (1-2ì„¸ ì¶”ì •)"
        elif any(year in age_str for year in ['2022', '2021', '2020']):
            return "ì Šì€ ì„±ì²´ (3-5ì„¸ ì¶”ì •)"
        elif any(year in age_str for year in ['2019', '2018', '2017']):
            return "ì¤‘ë…„ ë™ë¬¼ (6-8ì„¸ ì¶”ì •)"
        elif any(year in age_str for year in ['2016', '2015', '2014', '2013']):
            return "ê³ ë ¹ ë™ë¬¼ (9ì„¸ ì´ìƒ ì¶”ì •)"
        else:
            return f"ë‚˜ì´ ê´€ë ¨ ì •ë³´: {age_info}"
    
    def clean_text_for_gpt(self, text):
        """GPTê°€ ì´í•´í•˜ê¸° ì‰½ë„ë¡ í…ìŠ¤íŠ¸ ì •ë¦¬"""
        if pd.isna(text) or text == '':
            return ''
        
        text = str(text)
        
        # 1. í•´ì‹œíƒœê·¸ë¥¼ ìì—°ì–´ë¡œ ë³€í™˜ (#ì• êµìŸì´ â†’ ì• êµìŸì´)
        # GPTê°€ í•´ì‹œíƒœê·¸ë„ ì¶©ë¶„íˆ ì´í•´í•˜ë¯€ë¡œ ë‹¨ìˆœ ë³€í™˜ë§Œ
        text = re.sub(r'#([ê°€-í£a-zA-Z0-9]+)', r'\1', text)
        
        # 2. ê¸°ë³¸ì ì¸ ì •ë¦¬ë§Œ ìˆ˜í–‰
        text = re.sub(r'&apos;', "'", text)  # HTML ì—”í‹°í‹°
        text = re.sub(r'\r\n', ' ', text)    # ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ
        text = re.sub(r'\n', ' ', text)      # ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ
        text = re.sub(r'\s+', ' ', text)     # ì—°ì† ê³µë°± ì œê±°
        
        return text.strip()
    
    def create_comprehensive_description(self, row):
        """ê° ë™ë¬¼ì˜ ì¢…í•©ì ì¸ ìì—°ì–´ ì„¤ëª… ìƒì„±"""
        
        # ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘
        name = row.get('addinfo01', 'ì´ë¦„ë¯¸ì •')
        gender = row.get('addinfo03', 'ì„±ë³„ë¯¸ì •')
        weight = row.get('addinfo07')
        age_info = row.get('addinfo05', 'ë‚˜ì´ì •ë³´ì—†ìŒ')
        neuter = row.get('addinfo04', 'ì¤‘ì„±í™”ì—¬ë¶€ë¯¸ì •')
        state = row.get('state', 'ì…ì–‘ìƒíƒœë¯¸ì •')
        kind = row.get('kind', 'ì„ë³´ì¢…ë¥˜ë¯¸ì •')
        
        # í¬ê¸°ì™€ ë‚˜ì´ ì„¤ëª… ìƒì„±
        size_desc = self.create_size_category(weight)
        age_desc = self.create_age_description(age_info)
        
        # í…ìŠ¤íŠ¸ í•„ë“œë“¤ ì •ë¦¬
        personality_tags = self.clean_text_for_gpt(row.get('addinfo08', ''))
        rescue_story = self.clean_text_for_gpt(row.get('addinfo09', ''))
        personality_desc = self.clean_text_for_gpt(row.get('addinfo10', ''))
        additional_info = self.clean_text_for_gpt(row.get('addinfo11', ''))
        special_needs = self.clean_text_for_gpt(row.get('addinfo16', ''))
        daily_care = self.clean_text_for_gpt(row.get('addinfo20', ''))
        health_info = self.clean_text_for_gpt(row.get('addinfo19', ''))
        
        # ìì—°ì–´ ì„¤ëª… êµ¬ì„±
        description_parts = []
        
        # 1. ê¸°ë³¸ ì†Œê°œ
        intro = f"{name}ëŠ” {gender}ì´ë©°, {size_desc}ì— í•´ë‹¹í•©ë‹ˆë‹¤."
        if age_desc != "ë‚˜ì´ ì •ë³´ ì—†ìŒ":
            intro += f" {age_desc}ì´ê³ "
        if neuter and neuter != 'ì¤‘ì„±í™”ì—¬ë¶€ë¯¸ì •':
            intro += f" {neuter} ìƒíƒœì…ë‹ˆë‹¤."
        else:
            intro += "ì…ë‹ˆë‹¤."
        description_parts.append(intro)
        
        # 2. í˜„ì¬ ìƒíƒœ
        if state != 'ì…ì–‘ìƒíƒœë¯¸ì •' or kind != 'ì„ë³´ì¢…ë¥˜ë¯¸ì •':
            status = f"í˜„ì¬ {state} ìƒíƒœì´ë©° {kind}ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤."
            description_parts.append(status)
        
        # 3. ì„±ê²© íŠ¹ì§•
        if personality_tags:
            description_parts.append(personality_tags)
        
        # 4. ì„±ê²© ìƒì„¸ ì„¤ëª…
        if personality_desc:
            description_parts.append(f"ì„±ê²© ìƒì„¸: {personality_desc}")
        
        # 5. êµ¬ì¡° ë°°ê²½
        if rescue_story:
            description_parts.append(f"êµ¬ì¡° ë°°ê²½: {rescue_story}")
        
        # 6. ê±´ê°• ì •ë³´
        if health_info:
            description_parts.append(f"ê±´ê°• ìƒíƒœ: {health_info}")
        
        # 7. íŠ¹ë³„ ìš”êµ¬ì‚¬í•­
        if special_needs:
            description_parts.append(f"íŠ¹ë³„ ìš”êµ¬ì‚¬í•­: {special_needs}")
        
        # 8. ì¼ìƒ ê´€ë¦¬
        if daily_care:
            description_parts.append(f"ì¼ìƒ ê´€ë¦¬: {daily_care}")
        
        # 9. ì¶”ê°€ ì •ë³´
        if additional_info:
            description_parts.append(f"ì¶”ê°€ ì •ë³´: {additional_info}")
        
        # ìµœì¢… ì„¤ëª… ê²°í•©
        final_description = ' '.join(description_parts)
        
        return final_description
    
    def process_for_gpt_embedding(self, file_path):
        """GPT ì„ë² ë”©ì„ ìœ„í•œ ì „ì²´ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        print("ğŸ¤– GPT ì„ë² ë”©ìš© ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        print("=" * 50)
        
        # 1. ë°ì´í„° ë¡œë”©
        df = self.load_data(file_path)
        
        # 2. ê¸°ë³¸ ì •ë¦¬
        df = self.basic_cleaning(df)
        
        # 3. ê²°ì¸¡ê°’ ì²˜ë¦¬
        df = self.handle_missing_values(df)
        
        # 4. ìì—°ì–´ ì„¤ëª… ìƒì„±
        print("\nğŸ“ ìì—°ì–´ ì„¤ëª… ìƒì„± ì¤‘...")
        descriptions = []
        
        for idx, row in df.iterrows():
            description = self.create_comprehensive_description(row)
            descriptions.append(description)
            
            # ì§„í–‰ë¥  í‘œì‹œ
            if (idx + 1) % 500 == 0:
                print(f"   ì§„í–‰ë¥ : {idx + 1}/{len(df)} ({((idx + 1)/len(df)*100):.1f}%)")
        
        # 5. ì„¤ëª… í…ìŠ¤íŠ¸ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
        df['gpt_description'] = descriptions
        
        # ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
        self.processed_df = df
        
        print(f"\nâœ… GPT ì„ë² ë”©ìš© ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"   - ìµœì¢… ë°ì´í„° í¬ê¸°: {len(df)}ê°œ")
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ í†µê³„
        desc_lengths = [len(desc) for desc in descriptions]
        print(f"   - í‰ê·  ì„¤ëª… ê¸¸ì´: {np.mean(desc_lengths):.0f}ì")
        print(f"   - ìµœëŒ€ ì„¤ëª… ê¸¸ì´: {max(desc_lengths)}ì")
        print(f"   - ìµœì†Œ ì„¤ëª… ê¸¸ì´: {min(desc_lengths)}ì")
        
        return df, descriptions
    
    def save_processed_data(self, output_path="gpt_preprocessed_data.pkl"):
        """ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        print(f"\nğŸ’¾ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì¤‘: {output_path}")
        
        processed_data = {
            'dataframe': self.processed_df,
            'descriptions': self.processed_df['gpt_description'].tolist(),
            'metadata': {
                'total_records': len(self.processed_df),
                'preprocessing_type': 'GPT_embedding_optimized',
                'columns': list(self.processed_df.columns)
            }
        }
        
        with open(output_path, 'wb') as f:
            pickle.dump(processed_data, f)
        
        print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_path}")
    
    def sample_results(self, n=3):
        """ì²˜ë¦¬ ê²°ê³¼ ìƒ˜í”Œ í™•ì¸"""
        print(f"\nğŸ” GPT ì „ì²˜ë¦¬ ê²°ê³¼ ìƒ˜í”Œ ({n}ê°œ)")
        print("-" * 80)
        
        for i in range(min(n, len(self.processed_df))):
            row = self.processed_df.iloc[i]
            
            print(f"\nã€ë™ë¬¼ {i+1}: {row['addinfo01']}ã€‘")
            print(f"ìƒì„±ëœ ìì—°ì–´ ì„¤ëª…:")
            print(f"   {row['gpt_description'][:300]}...")
            print(f"   (ì´ {len(row['gpt_description'])}ì)")

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # GPTìš© ì „ì²˜ë¦¬ ê°ì²´ ìƒì„±
    gpt_processor = AnimalDataProcessorForGPT()
    
    # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    df, descriptions = gpt_processor.process_for_gpt_embedding('homeprotection_data.csv')
    
    # ê²°ê³¼ ìƒ˜í”Œ í™•ì¸
    gpt_processor.sample_results(3)
    
    # ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
    gpt_processor.save_processed_data()
    
    print("\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„: GPT ì„ë² ë”© ìƒì„±")
    print("   â†’ GPTEmbeddingProcessorë¡œ ì„ë² ë”© ë²¡í„° ìƒì„±")